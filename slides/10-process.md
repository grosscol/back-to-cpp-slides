---
author: Colin Gross
title: Adding Data to Bravo
date: 2023-10-12
---

# Processing eQTL Data
- What is present.
- How to integrate with existing data.
- Making a pipeline.

## Data Structure
Wonderfully written readme describing the data and procees by which it was generated by Peter Orchard.

```md
code book exerpt here
```

## Integration with Exisiting Data
- Finding common fields (position, gene\_id)
- Normalizing required

```txt
Existing data sample with gene_id
```

```txt
Incoming rows with ensembl_id
```

## Working Out Processing
- Remove trailing version numbers from Ensemble gene ids (column 1)
- Add tissue origin column as last column

```sh
awk 'BEGIN {FS="\t"; OFS=FS}\
  (NR>1) { sub(/\\.[[:digit:]]+$/,"",$1); \
  print $0 OFS "${tissue_type}" }' ${tissue_tsv} \
    > ${tissue_type}.${analysis_type}.tsv
```

## Making a Nextflow Workflows
Nextflow V2 DSL organizes a workflow into smaller units of named workflows.

```nf
workflow {
  conditional_eqtl()
  susie_eqtl()
}
```

### Named Workflow
```nf
workflow susie_eqtl {
  analysis_type = "susie"
  susie_tsv     = channel.fromPath("${params.susie_eqtl_glob}")
  susie_headers = channel.of(params.susie_fields).collect()
  fields        = params.susie_fields
  types         = params.susie_types

  validate_header(susie_tsv, susie_headers)
  munge_files(susie_tsv, analysis_type)
  merge_files(munge_files.out.collect(), 
              analysis_type, fields, types)
}
```
